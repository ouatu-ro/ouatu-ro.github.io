{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Closures and Partial Function Application in Python: A NLP Use Case\"\n",
    "pubDate: 2021-11-06T02:53:16+02:00\n",
    "description: \"This article explores closures and partial function application in Python, demonstrating how these powerful concepts can simplify state management and encapsulation. Through practical examples from NLP pipelines, including SpaCy and skweak, you'll learn common pitfalls, effective solutions, and best practices to write cleaner, more maintainable Python code.\"\n",
    "math: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While creating some pipelines for automatic text annotation, I encountered a bug that made me realize I didn't fully understand how closures work in Python. It's important to note that in Python, a for-loop does not create a new scope or its own context, which can affect how closures behave. <!--more-->\n",
    "\n",
    "When you're working with multiple packages in Python, you're essentially dealing with a complex ecosystem of code. You might often find that modifying components—be they functions, classes, or modules—is either impractical or impossible. This is especially true when those components are part of packages that are not under your control. Here's where closures can provide value:\n",
    "\n",
    "1. **Data Encapsulation**: Closures can enclose state—variables from the outer function that the inner function relies on. This encapsulation can effectively isolate this pocket of state, minimizing the risk of unintended side-effects when integrating with external packages.\n",
    "   \n",
    "2. **Idiomatic Code**: Pythonic idioms encourage readability and simplicity. Using closures can be a more Pythonic way to achieve specific kinds of encapsulation and state management without resorting to creating full-blown classes.\n",
    "  \n",
    "3. **Reduced Mental Overhead**: When you're wrestling with a complex system, every bit of simplification helps. Closures can help you encapsulate specific behaviors and states into individual, manageable units without requiring you to understand or modify the complete architecture of an external package.\n",
    "\n",
    "By focusing on these benefits, closures can sometimes serve as a more straightforward, clean alternative to complex inheritance hierarchies or class compositions when dealing with multiple external packages.\n",
    "\n",
    "In this article, I'll demonstrate the concept reconstructing functionalities from [SpaCy](https://spacy.io/) and [skweak](https://github.com/NorskRegnesentral/skweak). By the end, you should have a solid grasp of when and why to use closures, particularly in the context of Natural Language Processing (NLP).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are Closures?\n",
    "\n",
    "Before we dive into the problem I encountered, let's briefly talk about what closures are. A closure in Python is a function object that has access to variables in its local scope even after the function has finished execution. This allows for data to be hidden from the global scope, making it possible to encapsulate logic and state within a function.\n",
    "\n",
    "Here's a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def outer_function(x):\n",
    "    def inner_function(y):\n",
    "        return x + y\n",
    "    return inner_function\n",
    "\n",
    "x = -2  # this won't be seen by the inner_function, since it already sees the x from outer_function\n",
    "add_five = outer_function(x=5)\n",
    "result = add_five(y=3)\n",
    "print(result)  # Output will be 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy objects\n",
    "\n",
    "[SpaCy](https://spacy.io/) is here for you to help you build easy NLP pypelines.\n",
    "Central to this package are the `Doc` objects (short for document). It's a neatly way to pack data for NLP and if it doesn't provide what you need out of the box, you can [always extend it's functionalities](https://spacy.io/usage/processing-pipelines#custom-components-attributes) to match your usecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Generator, Iterable, List\n",
    "\n",
    "class Doc:\n",
    "    def __init__(self, text) -> None:\n",
    "        self.text = text\n",
    "        self.tokens: List[str] = text.split()\n",
    "        self.spans: Span = []\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    def __getitem__(self, position):\n",
    "        return self.tokens[position]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By implementing `__len__` and `__getitem__` [double-under functions](https://www.geeksforgeeks.org/dunder-magic-methods-python/) we got the ability to iterate through the Doc's tokens with a simple for as below. This is thanks to the Python datamodel. It's outside the scope of this post, but learning to leverage the datamodel will pay dividends on your effectiveness in Python. [Fluent Python](https://learning.oreilly.com/library/view/fluent-python/9781491946237/) introduces it in the first chapter in a very neat way. If you like video format more, [James Powell](https://www.youtube.com/watch?v=AmHE0kZhLIQ) got you covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today\n",
      "I\n",
      "ate\n",
      "garbonzo\n",
      "beans\n"
     ]
    }
   ],
   "source": [
    "doc = Doc(\"Today I ate garbonzo beans\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Span` is a slice of a `Doc`. Usually it can.. span multiple tokens, but today I have a feeling that all the spans we'll look at will match exactly one token. Also, in our case the spans will be always labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Span(NamedTuple):\n",
    "    position: int\n",
    "    label: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skweak functions\n",
    "If you haven't looked at the [skweak repo](https://github.com/NorskRegnesentral/skweak) yet, it suffices to know that it provides a neat way of composing simple annotators to get a better one.\n",
    "Now, skweak provides us with some very interesting classes. One is a `FunctionAnnotator`. This takes a function that returns a list of spans from a document and attaches these spans to the given document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionAnnotator:\n",
    "    def __init__(self, function: Callable[[Doc], Iterable[Span]]):\n",
    "        self.find_spans = function\n",
    "\t\t\n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        # We start by clearing all existing annotations\n",
    "        doc.spans = []\n",
    "\n",
    "        for position, label in self.find_spans(doc):\n",
    "            doc.spans.append(Span(position, label))\n",
    "\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a simple labeling function we may use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=1, label='ANIMAL'), Span(position=6, label='ANIMAL')]\n"
     ]
    }
   ],
   "source": [
    "def animal_labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "    for position, token in enumerate(doc.tokens):\n",
    "        if token.startswith('a'):\n",
    "            yield Span(position, 'ANIMAL')\n",
    "\n",
    "doc = Doc('this animal is some kind of antilope')\n",
    "animal_annotator = FunctionAnnotator(animal_labeling_function)\n",
    "doc = animal_annotator(doc)\n",
    "\n",
    "print(doc.spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FunctionAnnotatorAggregator` takes multiple annotator functions and combines them in some fancy way. We won't do it justice with the implementation below.\n",
    "We'll just make it force our documents to have a maximum of one label per span. We will also sort them by the order of appearance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionAnnotatorAggregator:\n",
    "    \"\"\"Base aggregator to combine all labelling sources into a single annotation layer\"\"\"\n",
    "    def __init__(self, annotators: Iterable[FunctionAnnotator]) -> None:\n",
    "        self.annotators = annotators\n",
    "    \n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        spans_dict = dict()\n",
    "        for annotator in self.annotators:\n",
    "            for span in annotator(doc).spans:\n",
    "                spans_dict[span.position] = span.label\n",
    "        \n",
    "        doc.spans = []\n",
    "        for position, label in spans_dict.items():\n",
    "            doc.spans.append(Span(position, label))\n",
    "        doc.spans.sort()\n",
    "        \n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=1, label='ANIMAL'), Span(position=2, label='VERB'), Span(position=6, label='ANIMAL')]\n"
     ]
    }
   ],
   "source": [
    "def verb_labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "    for position, token in enumerate(doc.tokens):\n",
    "        if token in ['is', 'has']:\n",
    "            yield Span(position, 'VERB')\n",
    "\n",
    "verb_annotator = FunctionAnnotator(verb_labeling_function)\n",
    "\n",
    "aggregated_annotator = FunctionAnnotatorAggregator([animal_annotator, verb_annotator])\n",
    "\n",
    "doc = aggregated_annotator(doc)\n",
    "\n",
    "print(doc.spans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem\n",
    "\n",
    "The packages are well implemented and work as expected! \n",
    "Now, we may wish to programatically generate some labeling functions from a list of excellent heuristic parameters\n",
    "<a id='problem_cell'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_parameters = [\n",
    "    ('M', 'MAMMAL'),\n",
    "    ('F', 'FISH'),\n",
    "    ('B', 'BIRD')\n",
    "    ]\n",
    "\n",
    "labeling_functions = []\n",
    "for strats_with, label in heuristic_parameters:\n",
    "    def labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "        for position, word in enumerate(doc.tokens):\n",
    "            if word.startswith(strats_with):\n",
    "                yield Span(position, label)\n",
    "    labeling_functions += [labeling_function]\n",
    "\n",
    "strats_with, label = 'B', 'BOVINE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='problem_cell_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=6, label='BOVINE')]\n"
     ]
    }
   ],
   "source": [
    "doc = Doc(\"Monkeys are red. Firefish are blue; Besra is a bird and so are you\")\n",
    "\n",
    "# we'll define this function since we'll use it a lot more below\n",
    "def print_spans_from_labelers(doc, labeling_functions):\n",
    "    annotators = [FunctionAnnotator(labeling_function) for labeling_function in labeling_functions]\n",
    "    aggregated_annotator = FunctionAnnotatorAggregator(annotators)\n",
    "\n",
    "    doc = aggregated_annotator(doc)\n",
    "\n",
    "    print(doc.spans)\n",
    "print_spans_from_labelers(doc, labeling_functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? It seems that only the last function was applied. Let's look at the `labeling_functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function labeling_function at 0x10372e200>\n",
      "<function labeling_function at 0x10372f1c0>\n",
      "<function labeling_function at 0x10372f250>\n"
     ]
    }
   ],
   "source": [
    "for labeling_function in labeling_functions:\n",
    "    print(labeling_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They point to different memory addresses.\n",
    "Let's rewrite this with lambda functions. \n",
    "\n",
    "*Note* if you haven't worked with list comprehensions before: don't worry about it; think of the code below as a way to create a new function without replacing the existing function with the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <listcomp>.<lambda> at 0x10372dc60>\n",
      "<function <listcomp>.<lambda> at 0x10372f490>\n",
      "<function <listcomp>.<lambda> at 0x10372f5b0>\n"
     ]
    }
   ],
   "source": [
    "labeling_functions = [\n",
    "                        lambda doc: \n",
    "                            ( # this is also a generator in Python; it's the same syntax as list comprehension\n",
    "                            # but we use round braces instead of square ones\n",
    "                                Span(position, label) \n",
    "                                    for position, word in enumerate(doc.tokens) \n",
    "                                    if word.startswith(strats_with)\n",
    "                            )\n",
    "                        for strats_with, label in heuristic_parameters\n",
    "                    ]\n",
    "\n",
    "for labeling_function in labeling_functions:\n",
    "    print(labeling_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when we want to print the function the problem stays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=6, label='BIRD')]\n"
     ]
    }
   ],
   "source": [
    "print_spans_from_labelers(doc, labeling_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because of scoping. The problem is that, since we didn't declare strats_with, label in the lambda body or parameters, the lambdas will always look in the scope immediately outside them and they will find the last values that `strats_with`, `label` had.\n",
    "If you come from other languages it might be strange to you, but Python doesn't create a new scope or context inside the `for` body. Instead it uses the same local scope. This is why `strats_with, label = 'B', 'BOVINE'` in snippet [8](#problem_cell) produced snippet [9](#problem_cell_2) to display the label as 'BOVINE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "But be not affraid! There is a solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_closure(strats_with, label):\n",
    "    local_strats_with, local_label = strats_with, label\n",
    "    def labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "        for position, word in enumerate(doc.tokens):\n",
    "            if word.startswith(local_strats_with):\n",
    "                yield Span(position, local_label)\n",
    "    return labeling_function\n",
    "\n",
    "labeling_functions = [function_closure(strats_with, label) for strats_with, label in heuristic_parameters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we get the annotators things go as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=0, label='MAMMAL'), Span(position=3, label='FISH'), Span(position=6, label='BIRD')]\n"
     ]
    }
   ],
   "source": [
    "print_spans_from_labelers(doc, labeling_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But why is this different from the last attempt? This time, by calling `function_closure` we are creating a local scope around the labeling function and put the `strats_with` and `label` variables in it. These variables are recreated every time we call `function_closure`. It also recreates `labeling_function` since functions are regular objects in Python and different calls can’t trample on one another’s local variables. \n",
    "\n",
    "A good mental model is to think of function values as containing both the code in their body and the environment in which they are created.*\n",
    "\n",
    "*lifted from [*Eloquent Javascript*](https://eloquentjavascript.net/03_functions.html) book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the functions will also confirm this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function function_closure.<locals>.labeling_function at 0x10372f640>\n",
      "<class 'function'>\n"
     ]
    }
   ],
   "source": [
    "print(repr(labeling_functions[0]))\n",
    "print(type(labeling_functions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One improvement we can make is not using `local_strats_with`, `local_label`, since parameters are themselves local variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=0, label='MAMMAL'), Span(position=3, label='FISH'), Span(position=6, label='BIRD')]\n"
     ]
    }
   ],
   "source": [
    "def function_closure(strats_with, label):\n",
    "    def labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "        for position, word in enumerate(doc.tokens):\n",
    "            if word.startswith(strats_with):\n",
    "                yield Span(position, label)\n",
    "    return labeling_function\n",
    "\n",
    "labeling_functions = [function_closure(strats_with, label) for strats_with, label in heuristic_parameters]\n",
    "print_spans_from_labelers(doc, labeling_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial function application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another way to do things, partial application is a concept where you fix a few arguments of a function and generate a new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=0, label='MAMMAL'), Span(position=3, label='FISH'), Span(position=6, label='BIRD')]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def labeling_function(starts_with, label, doc: Doc) -> Generator[Span, None, None]:\n",
    "    for position, word in enumerate(doc.tokens):\n",
    "        if word.startswith(starts_with):\n",
    "            yield Span(position, label)\n",
    "\n",
    "# Using partial to fix the first two arguments starts_with and label\n",
    "labeling_functions = [partial(labeling_function, starts_with, label) for starts_with, label in heuristic_parameters]\n",
    "\n",
    "# Verify if the partial application works as intended\n",
    "print_spans_from_labelers(doc, labeling_functions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "`labeling_function` is now a single function that accepts three parameters.\n",
    "\n",
    "We use `functools.partial` to \"lock in\" the first two parameters, `starts_with` and `label`.\n",
    "\n",
    "This generates a new function for each pair of `starts_with` and `label`, which we then add to `labeling_functions`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare it with how you'd implement a regular class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=0, label='MAMMAL'), Span(position=3, label='FISH'), Span(position=6, label='BIRD')]\n"
     ]
    }
   ],
   "source": [
    "class LabelingCallable:\n",
    "    def __init__(self, starts_with, label) -> None:\n",
    "        self.starts_with = starts_with\n",
    "        self.label = label\n",
    "\n",
    "    def __call__(self, doc) -> Generator[Span, None, None]:\n",
    "        for position, word in enumerate(doc.tokens):\n",
    "            if word.startswith(self.starts_with):\n",
    "                yield Span(position, self.label)\n",
    "\n",
    "labeling_functions = [LabelingCallable(strats_with, label) for strats_with, label in heuristic_parameters]\n",
    "print_spans_from_labelers(doc, labeling_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object is used only because it can function as a regular function - something that an actual regular function is more fit to do. This also requires you to come up with a naming convention for this kind of classes. And it doesn't fit with the fact that `skweak` expects a function (as the code and docstrings imply), even if it masquerades as one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Span(position=0, label='MAMMAL'), Span(position=3, label='FISH'), Span(position=6, label='BIRD')]\n",
      "<bound method LabelingCallable.labeling_function of <__main__.LabelingCallable object at 0x1037524a0>>\n",
      "<class 'method'>\n"
     ]
    }
   ],
   "source": [
    "class LabelingCallable:\n",
    "    def __init__(self, starts_with, label) -> None:\n",
    "        self.starts_with = starts_with\n",
    "        self.label = label\n",
    "\n",
    "    def labeling_function(self, doc) -> Generator[Span, None, None]:\n",
    "        for position, word in enumerate(doc.tokens):\n",
    "            if word.startswith(self.starts_with):\n",
    "                yield Span(position, self.label)\n",
    "\n",
    "labeling_functions = [LabelingCallable(strats_with, label).labeling_function for strats_with, label in heuristic_parameters]\n",
    "print_spans_from_labelers(doc, labeling_functions)\n",
    "print(repr(labeling_functions[0]))\n",
    "print(type(labeling_functions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe this is something you'll eventually want but, for our intended purposes, this is basically a closure with extra steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post we explored closures, a solution for providing data locality.\n",
    "\n",
    "As we've seen, Python closures and partial function application are powerful features for encapsulating local state. These techniques can be especially useful in NLP pipelines, allowing us to write clean, modular code. Whether you are working on a simple task or something complex like automated text annotation, understanding these language features can significantly improve your code quality and maintainability.\n",
    "\n",
    "If this is the kind of content you enjoy, let me know!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adf093301c14a63c6539f58cf0b8916c00ba44ee06fa6d5252f125346225c63b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('3.9.5': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
